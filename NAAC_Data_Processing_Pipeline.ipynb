{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171550c0",
   "metadata": {},
   "source": [
    "# ğŸ“ NAAC Data Processing Pipeline\n",
    "## Comprehensive AI Assistant Data Preparation\n",
    "\n",
    "This notebook implements the complete pipeline for processing NAAC datasets and documents to create an intelligent AI assistant capable of:\n",
    "\n",
    "- ğŸ“Š **Data Analysis**: Processing institutional data from Kaggle and Data.gov\n",
    "- ğŸ“„ **Document Processing**: Extracting and chunking text from SSRs, AQARs, and guidelines\n",
    "- ğŸ§  **Vector Search**: Creating embeddings for semantic similarity search\n",
    "- ğŸ¤– **RAG Implementation**: Building Retrieval-Augmented Generation pipeline with IBM Granite LLM\n",
    "- âœ… **Interactive Testing**: Validating the AI assistant's capabilities\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ **Pipeline Overview**\n",
    "\n",
    "1. **Setup Environment** - Install dependencies and configure paths\n",
    "2. **Organize Files** - Create structured directories for data management\n",
    "3. **Clean Tabular Data** - Process CSV/Excel files for metadata enrichment\n",
    "4. **Extract PDF Text** - Convert NAAC documents to searchable text\n",
    "5. **Chunk for RAG** - Split text into optimal retrieval segments\n",
    "6. **Create Vector DB** - Generate embeddings and build search index\n",
    "7. **Build RAG Pipeline** - Connect retrieval with IBM Granite LLM\n",
    "8. **Test Assistant** - Validate performance with real NAAC queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af2bda9",
   "metadata": {},
   "source": [
    "## ğŸ”§ Section 1: Setup Environment and Import Libraries\n",
    "\n",
    "First, we'll install and import all necessary libraries for data processing, text extraction, and RAG implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a096768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas openpyxl pdfplumber PyMuPDF langchain chromadb sentence-transformers\n",
    "!pip install langchain-community langchain-text-splitters\n",
    "!pip install huggingface-hub transformers torch\n",
    "\n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfplumber\n",
    "import json\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms.base import LLM\n",
    "\n",
    "# Set up paths\n",
    "BASE_DIR = Path(\"/home/hari/naac\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "CLEANED_DIR = DATA_DIR / \"cleaned\"\n",
    "DOCS_DIR = DATA_DIR / \"documents\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "print(\"ğŸ“š Libraries imported successfully!\")\n",
    "print(f\"ğŸ“ Base directory: {BASE_DIR}\")\n",
    "print(f\"ğŸ“Š Data directory: {DATA_DIR}\")\n",
    "print(f\"ğŸ“‹ Raw data: {RAW_DIR}\")\n",
    "print(f\"âœ¨ Cleaned data: {CLEANED_DIR}\")\n",
    "print(f\"ğŸ“„ Documents: {DOCS_DIR}\")\n",
    "print(f\"âš™ï¸ Processed: {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92cefd6",
   "metadata": {},
   "source": [
    "## ğŸ“ Section 2: Organize File Structure\n",
    "\n",
    "Create the proper directory structure for organized data management as per the step-by-step plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bfec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all directories exist\n",
    "directories = [DATA_DIR, RAW_DIR, CLEANED_DIR, DOCS_DIR, PROCESSED_DIR]\n",
    "for directory in directories:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âœ… Directory created/verified: {directory}\")\n",
    "\n",
    "# Check existing raw data files\n",
    "print(\"\\nğŸ“‹ Existing raw data files:\")\n",
    "raw_files = list(RAW_DIR.glob(\"*\"))\n",
    "for i, file in enumerate(raw_files, 1):\n",
    "    print(f\"  {i}. {file.name} ({file.stat().st_size / 1024:.1f} KB)\")\n",
    "\n",
    "if not raw_files:\n",
    "    print(\"  âš ï¸  No files found in raw data directory\")\n",
    "    print(\"  ğŸ’¡ Please ensure your datasets are in:\", RAW_DIR)\n",
    "else:\n",
    "    print(f\"\\nğŸ‰ Found {len(raw_files)} data files ready for processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e3e6b",
   "metadata": {},
   "source": [
    "## ğŸ” Section 3: Load and Clean Tabular Data\n",
    "\n",
    "Process CSV and Excel files from Kaggle and Data.gov to create clean, structured datasets for metadata enrichment and query filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, filename):\n",
    "    \"\"\"Clean and standardize a dataframe\"\"\"\n",
    "    print(f\"\\nğŸ§¹ Cleaning {filename}...\")\n",
    "    print(f\"   Original shape: {df.shape}\")\n",
    "    \n",
    "    # Store original shape\n",
    "    original_rows = len(df)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.astype(str).str.strip().str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # Remove completely empty rows\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    # Remove columns that are completely empty\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    \n",
    "    print(f\"   After cleaning: {df.shape}\")\n",
    "    print(f\"   Removed {original_rows - len(df)} empty rows\")\n",
    "    print(f\"   Columns: {list(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process CSV files\n",
    "csv_files = list(RAW_DIR.glob(\"*.csv\"))\n",
    "cleaned_datasets = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    try:\n",
    "        # Load CSV\n",
    "        df = pd.read_csv(csv_file, encoding='utf-8')\n",
    "        \n",
    "        # Clean the dataframe\n",
    "        df_clean = clean_dataframe(df, csv_file.name)\n",
    "        \n",
    "        # Save cleaned version\n",
    "        cleaned_filename = f\"cleaned_{csv_file.stem}.csv\"\n",
    "        cleaned_path = CLEANED_DIR / cleaned_filename\n",
    "        df_clean.to_csv(cleaned_path, index=False)\n",
    "        \n",
    "        # Store in memory for later use\n",
    "        cleaned_datasets[csv_file.stem] = df_clean\n",
    "        \n",
    "        print(f\"   âœ… Saved: {cleaned_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {csv_file.name}: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Successfully processed {len(cleaned_datasets)} CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Excel files\n",
    "excel_files = list(RAW_DIR.glob(\"*.xlsx\")) + list(RAW_DIR.glob(\"*.xls\"))\n",
    "\n",
    "for excel_file in excel_files:\n",
    "    try:\n",
    "        # Load Excel file (might have multiple sheets)\n",
    "        excel_data = pd.ExcelFile(excel_file)\n",
    "        print(f\"\\nğŸ“Š Processing {excel_file.name}\")\n",
    "        print(f\"   Sheets found: {excel_data.sheet_names}\")\n",
    "        \n",
    "        for sheet_name in excel_data.sheet_names:\n",
    "            # Read each sheet\n",
    "            df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
    "            \n",
    "            # Clean the dataframe\n",
    "            df_clean = clean_dataframe(df, f\"{excel_file.stem}_{sheet_name}\")\n",
    "            \n",
    "            # Save cleaned version\n",
    "            cleaned_filename = f\"cleaned_{excel_file.stem}_{sheet_name}.csv\"\n",
    "            cleaned_path = CLEANED_DIR / cleaned_filename\n",
    "            df_clean.to_csv(cleaned_path, index=False)\n",
    "            \n",
    "            # Store in memory\n",
    "            cleaned_datasets[f\"{excel_file.stem}_{sheet_name}\"] = df_clean\n",
    "            \n",
    "            print(f\"   âœ… Saved: {cleaned_path}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {excel_file.name}: {e}\")\n",
    "\n",
    "# Create summary of all datasets\n",
    "print(f\"\\nğŸ“ˆ Dataset Summary:\")\n",
    "print(f\"{'Dataset':<30} {'Rows':<8} {'Columns':<8} {'Size (KB)':<10}\")\n",
    "print(\"-\" * 56)\n",
    "\n",
    "total_rows = 0\n",
    "for name, df in cleaned_datasets.items():\n",
    "    size_kb = df.memory_usage(deep=True).sum() / 1024\n",
    "    total_rows += len(df)\n",
    "    print(f\"{name[:29]:<30} {len(df):<8} {len(df.columns):<8} {size_kb:<10.1f}\")\n",
    "\n",
    "print(\"-\" * 56)\n",
    "print(f\"{'TOTAL':<30} {total_rows:<8} {'':<8} {'':<10}\")\n",
    "print(f\"\\nğŸ‰ All tabular data cleaned and ready for use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c4f8c",
   "metadata": {},
   "source": [
    "## ğŸ“„ Section 4: Extract Text from PDF Documents\n",
    "\n",
    "Extract text content from NAAC SSRs, AQARs, and guideline documents using pdfplumber for reliable text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba5aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from PDF using pdfplumber\"\"\"\n",
    "    text_content = \"\"\n",
    "    page_count = 0\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            page_count = len(pdf.pages)\n",
    "            print(f\"   ğŸ“– Extracting from {page_count} pages...\")\n",
    "            \n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                try:\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text_content += f\"\\n--- Page {page_num} ---\\n\"\n",
    "                        text_content += page_text.strip()\n",
    "                        text_content += \"\\n\"\n",
    "                        \n",
    "                        if page_num % 10 == 0:  # Progress indicator\n",
    "                            print(f\"   â³ Processed {page_num}/{page_count} pages...\")\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"   âš ï¸  Error on page {page_num}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error opening PDF: {e}\")\n",
    "        return None, 0\n",
    "    \n",
    "    return text_content.strip(), page_count\n",
    "\n",
    "# Look for PDF files in documents directory and raw directory\n",
    "pdf_files = list(DOCS_DIR.glob(\"*.pdf\")) + list(RAW_DIR.glob(\"*.pdf\"))\n",
    "extracted_texts = {}\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"ğŸ“ No PDF files found. Creating sample placeholder...\")\n",
    "    \n",
    "    # Create a sample NAAC document for demonstration\n",
    "    sample_content = \"\"\"\n",
    "NATIONAL ASSESSMENT AND ACCREDITATION COUNCIL (NAAC)\n",
    "Self Study Report (SSR)\n",
    "\n",
    "1. EXECUTIVE SUMMARY\n",
    "\n",
    "1.1 INTRODUCTION\n",
    "The institution is committed to providing quality higher education and has established comprehensive mechanisms for quality assurance. This Self Study Report (SSR) presents a detailed analysis of the institution's performance across seven criteria.\n",
    "\n",
    "1.2 INSTITUTIONAL PROFILE\n",
    "Name of the Institution: Sample College\n",
    "Year of Establishment: 1985\n",
    "Type: Government/Government Aided/Self-financing\n",
    "Academic Programs: Undergraduate, Postgraduate, Research\n",
    "\n",
    "2. INSTITUTIONAL PREPAREDNESS FOR ACCREDITATION\n",
    "\n",
    "2.1 QUALITY POLICY\n",
    "The institution has a well-defined quality policy that emphasizes excellence in teaching, learning, and research.\n",
    "\n",
    "2.2 IQAC (Internal Quality Assurance Cell)\n",
    "The IQAC functions effectively with regular meetings and quality enhancement initiatives.\n",
    "\n",
    "3. CRITERIA-WISE ANALYSIS\n",
    "\n",
    "3.1 CRITERIA I: CURRICULAR ASPECTS\n",
    "The institution offers diverse programs aligned with university guidelines and industry requirements.\n",
    "\n",
    "3.2 CRITERIA II: TEACHING-LEARNING AND EVALUATION\n",
    "Innovative teaching methodologies and fair evaluation practices are implemented.\n",
    "\n",
    "3.3 CRITERIA III: RESEARCH, INNOVATIONS AND EXTENSION\n",
    "The institution encourages research activities and community engagement.\n",
    "\n",
    "3.4 CRITERIA IV: INFRASTRUCTURE AND LEARNING RESOURCES\n",
    "Adequate infrastructure and modern learning resources support academic activities.\n",
    "\n",
    "3.5 CRITERIA V: STUDENT SUPPORT AND PROGRESSION\n",
    "Comprehensive student support services ensure holistic development.\n",
    "\n",
    "3.6 CRITERIA VI: GOVERNANCE, LEADERSHIP AND MANAGEMENT\n",
    "Effective governance structures and leadership promote institutional growth.\n",
    "\n",
    "3.7 CRITERIA VII: INSTITUTIONAL VALUES AND BEST PRACTICES\n",
    "The institution upholds ethical values and implements innovative best practices.\n",
    "\n",
    "4. CONCLUSION\n",
    "The institution demonstrates commitment to quality education and continuous improvement.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save sample document\n",
    "    sample_path = DOCS_DIR / \"sample_naac_ssr.txt\"\n",
    "    with open(sample_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(sample_content)\n",
    "    \n",
    "    extracted_texts['sample_naac_ssr'] = sample_content\n",
    "    print(f\"   âœ… Created sample document: {sample_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"ğŸ“š Found {len(pdf_files)} PDF files to process:\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nğŸ“„ Processing: {pdf_file.name}\")\n",
    "        \n",
    "        # Extract text\n",
    "        text_content, page_count = extract_text_from_pdf(pdf_file)\n",
    "        \n",
    "        if text_content:\n",
    "            # Save extracted text\n",
    "            text_filename = f\"{pdf_file.stem}_extracted.txt\"\n",
    "            text_path = PROCESSED_DIR / text_filename\n",
    "            \n",
    "            with open(text_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(text_content)\n",
    "            \n",
    "            # Store in memory\n",
    "            extracted_texts[pdf_file.stem] = text_content\n",
    "            \n",
    "            word_count = len(text_content.split())\n",
    "            print(f\"   âœ… Extracted {word_count:,} words from {page_count} pages\")\n",
    "            print(f\"   ğŸ’¾ Saved to: {text_path}\")\n",
    "        else:\n",
    "            print(f\"   âŒ Failed to extract text from {pdf_file.name}\")\n",
    "\n",
    "print(f\"\\nğŸ“– Text extraction complete!\")\n",
    "print(f\"   ğŸ“š Total documents processed: {len(extracted_texts)}\")\n",
    "total_words = sum(len(text.split()) for text in extracted_texts.values())\n",
    "print(f\"   ğŸ“ Total words extracted: {total_words:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb6a1b",
   "metadata": {},
   "source": [
    "## ğŸ§© Section 5: Chunk Text for RAG Implementation\n",
    "\n",
    "Break the extracted text into meaningful chunks using LangChain's RecursiveCharacterTextSplitter for optimal retrieval performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681dc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure text splitter for optimal chunk size\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # Optimal size for semantic coherence\n",
    "    chunk_overlap=150,      # Overlap to maintain context\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Prioritize natural breaks\n",
    ")\n",
    "\n",
    "print(\"ğŸ§© Chunking text documents for RAG...\")\n",
    "print(f\"   Chunk size: 1000 characters\")\n",
    "print(f\"   Overlap: 150 characters\")\n",
    "\n",
    "all_chunks = []\n",
    "chunk_metadata = []\n",
    "\n",
    "for doc_name, text_content in extracted_texts.items():\n",
    "    print(f\"\\nğŸ“„ Chunking: {doc_name}\")\n",
    "    \n",
    "    # Split text into chunks\n",
    "    chunks = text_splitter.split_text(text_content)\n",
    "    \n",
    "    print(f\"   ğŸ“Š Created {len(chunks)} chunks\")\n",
    "    \n",
    "    # Create Document objects with metadata\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Create document with metadata\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"source\": doc_name,\n",
    "                \"chunk_id\": f\"{doc_name}_chunk_{i+1}\",\n",
    "                \"chunk_index\": i,\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"doc_type\": \"naac_document\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        all_chunks.append(doc)\n",
    "        \n",
    "        # Store metadata for analysis\n",
    "        chunk_metadata.append({\n",
    "            \"source\": doc_name,\n",
    "            \"chunk_id\": f\"{doc_name}_chunk_{i+1}\",\n",
    "            \"chunk_size\": len(chunk),\n",
    "            \"chunk_index\": i\n",
    "        })\n",
    "    \n",
    "    # Show preview of first chunk\n",
    "    if chunks:\n",
    "        preview = chunks[0][:200] + \"...\" if len(chunks[0]) > 200 else chunks[0]\n",
    "        print(f\"   ğŸ“– Preview: {preview}\")\n",
    "\n",
    "# Save chunks for future use\n",
    "chunks_path = PROCESSED_DIR / \"text_chunks.json\"\n",
    "chunks_data = {\n",
    "    \"chunks\": [{\"content\": doc.page_content, \"metadata\": doc.metadata} for doc in all_chunks],\n",
    "    \"total_chunks\": len(all_chunks),\n",
    "    \"processing_timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "with open(chunks_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(chunks_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nâœ… Text chunking complete!\")\n",
    "print(f\"   ğŸ“š Total chunks created: {len(all_chunks)}\")\n",
    "print(f\"   ğŸ“Š Average chunk size: {np.mean([len(doc.page_content) for doc in all_chunks]):.0f} characters\")\n",
    "print(f\"   ğŸ’¾ Chunks saved to: {chunks_path}\")\n",
    "\n",
    "# Display chunk distribution\n",
    "chunk_sizes = [len(doc.page_content) for doc in all_chunks]\n",
    "print(f\"   ğŸ“ˆ Chunk size distribution:\")\n",
    "print(f\"      Min: {min(chunk_sizes)} characters\")\n",
    "print(f\"      Max: {max(chunk_sizes)} characters\")\n",
    "print(f\"      Median: {np.median(chunk_sizes):.0f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6896859",
   "metadata": {},
   "source": [
    "## ğŸ§  Section 6: Create Vector Embeddings and Database\n",
    "\n",
    "Generate embeddings using HuggingFace models and store them in ChromaDB for efficient similarity search and retrieval operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0034e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§  Setting up embeddings and vector database...\")\n",
    "\n",
    "# Initialize embedding model\n",
    "print(\"   ğŸ”§ Loading HuggingFace embedding model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # Fast and efficient\n",
    "    model_kwargs={'device': 'cpu'},  # Use CPU for compatibility\n",
    "    encode_kwargs={'normalize_embeddings': True}  # Normalize for better similarity\n",
    ")\n",
    "\n",
    "print(\"   âœ… Embedding model loaded successfully!\")\n",
    "\n",
    "# Set up ChromaDB path\n",
    "chroma_db_path = PROCESSED_DIR / \"chroma_db\"\n",
    "chroma_db_path.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"   ğŸ“ Vector database path: {chroma_db_path}\")\n",
    "\n",
    "# Create vector database\n",
    "print(\"   ğŸ—„ï¸ Creating vector database...\")\n",
    "print(f\"   ğŸ“Š Processing {len(all_chunks)} text chunks...\")\n",
    "\n",
    "# Create ChromaDB vector store\n",
    "try:\n",
    "    vector_db = Chroma.from_documents(\n",
    "        documents=all_chunks,\n",
    "        embedding=embedding_model,\n",
    "        persist_directory=str(chroma_db_path),\n",
    "        collection_name=\"naac_documents\"\n",
    "    )\n",
    "    \n",
    "    # Persist the database\n",
    "    vector_db.persist()\n",
    "    \n",
    "    print(\"   âœ… Vector database created successfully!\")\n",
    "    \n",
    "    # Test the database\n",
    "    print(\"\\nğŸ” Testing vector database...\")\n",
    "    test_query = \"NAAC accreditation criteria\"\n",
    "    test_results = vector_db.similarity_search(test_query, k=3)\n",
    "    \n",
    "    print(f\"   ğŸ” Test query: '{test_query}'\")\n",
    "    print(f\"   ğŸ“Š Retrieved {len(test_results)} similar chunks:\")\n",
    "    \n",
    "    for i, result in enumerate(test_results, 1):\n",
    "        preview = result.page_content[:100] + \"...\" if len(result.page_content) > 100 else result.page_content\n",
    "        source = result.metadata.get('source', 'Unknown')\n",
    "        print(f\"      {i}. Source: {source}\")\n",
    "        print(f\"         Preview: {preview}\")\n",
    "        print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error creating vector database: {e}\")\n",
    "    print(\"   ğŸ’¡ This might be due to missing dependencies. Installing...\")\n",
    "    \n",
    "    # Try to install missing dependencies\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"chromadb\", \"--quiet\"])\n",
    "        print(\"   âœ… ChromaDB installed. Please restart and try again.\")\n",
    "    except:\n",
    "        print(\"   âš ï¸  Manual installation required: pip install chromadb\")\n",
    "\n",
    "# Save vector database metadata\n",
    "db_metadata = {\n",
    "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"total_chunks\": len(all_chunks),\n",
    "    \"database_path\": str(chroma_db_path),\n",
    "    \"collection_name\": \"naac_documents\",\n",
    "    \"creation_timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"chunk_sources\": list(set([chunk.metadata['source'] for chunk in all_chunks]))\n",
    "}\n",
    "\n",
    "metadata_path = PROCESSED_DIR / \"vector_db_metadata.json\"\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(db_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nğŸ‰ Vector database setup complete!\")\n",
    "print(f\"   ğŸ—„ï¸ Database location: {chroma_db_path}\")\n",
    "print(f\"   ğŸ“Š Total vectors: {len(all_chunks)}\")\n",
    "print(f\"   ğŸ“ Metadata saved: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f74e4d3",
   "metadata": {},
   "source": [
    "## ğŸ¤– Section 7: Build RAG Pipeline with LangChain\n",
    "\n",
    "Implement RetrievalQA chain connecting the vector database with IBM Granite LLM for question-answering capabilities on NAAC documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables for IBM Cloud\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/hari/naac/naac-frontend/.env\")  # Load from your .env file\n",
    "\n",
    "class IBMGraniteLLM(LLM):\n",
    "    \"\"\"Custom LLM wrapper for IBM Granite model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.api_key = os.getenv(\"REACT_APP_IBM_CLOUD_API_KEY\")\n",
    "        self.model_id = os.getenv(\"REACT_APP_IBM_GRANITE_MODEL_ID\", \"ibm/granite-13b-chat-v2\")\n",
    "        self.url = os.getenv(\"REACT_APP_IBM_GRANITE_URL\")\n",
    "        self.project_id = os.getenv(\"REACT_APP_IBM_PROJECT_ID\")\n",
    "        \n",
    "        if not all([self.api_key, self.url, self.project_id]):\n",
    "            print(\"âš ï¸  IBM Granite credentials not found. Using mock responses.\")\n",
    "            self.mock_mode = True\n",
    "        else:\n",
    "            self.mock_mode = False\n",
    "            print(\"âœ… IBM Granite credentials loaded successfully!\")\n",
    "    \n",
    "    def _call(self, prompt: str, stop=None) -> str:\n",
    "        \"\"\"Call the IBM Granite model\"\"\"\n",
    "        if self.mock_mode:\n",
    "            return self._generate_mock_response(prompt)\n",
    "        \n",
    "        try:\n",
    "            headers = {\n",
    "                \"Authorization\": f\"Bearer {self._get_access_token()}\",\n",
    "                \"Content-Type\": \"application/json\"\n",
    "            }\n",
    "            \n",
    "            payload = {\n",
    "                \"input\": prompt,\n",
    "                \"parameters\": {\n",
    "                    \"decoding_method\": \"greedy\",\n",
    "                    \"max_new_tokens\": 500,\n",
    "                    \"temperature\": 0.1\n",
    "                },\n",
    "                \"model_id\": self.model_id,\n",
    "                \"project_id\": self.project_id\n",
    "            }\n",
    "            \n",
    "            response = requests.post(self.url, headers=headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            return result.get(\"results\", [{}])[0].get(\"generated_text\", \"\").strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error calling IBM Granite: {e}\")\n",
    "            return self._generate_mock_response(prompt)\n",
    "    \n",
    "    def _get_access_token(self):\n",
    "        \"\"\"Get IBM Cloud access token\"\"\"\n",
    "        token_url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "        data = {\n",
    "            \"grant_type\": \"urn:ietf:params:oauth:grant-type:apikey\",\n",
    "            \"apikey\": self.api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.post(token_url, headers=headers, data=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"access_token\"]\n",
    "    \n",
    "    def _generate_mock_response(self, prompt: str) -> str:\n",
    "        \"\"\"Generate mock response when API is unavailable\"\"\"\n",
    "        if \"SSR\" in prompt.upper():\n",
    "            return \"\"\"Based on NAAC guidelines, an SSR (Self Study Report) should include:\n",
    "\n",
    "1. **Executive Summary**: Overview of institutional strengths and achievements\n",
    "2. **Institutional Profile**: Basic information about the institution\n",
    "3. **Criteria-wise Analysis**: Detailed analysis across all seven NAAC criteria\n",
    "4. **Supporting Documents**: Evidence and documentation for claims\n",
    "5. **SWOC Analysis**: Strengths, Weaknesses, Opportunities, and Challenges\n",
    "\n",
    "Each criterion should be thoroughly documented with quantitative and qualitative data.\"\"\"\n",
    "        \n",
    "        elif \"CRITERIA\" in prompt.upper() or \"CRITERION\" in prompt.upper():\n",
    "            return \"\"\"NAAC evaluates institutions based on seven key criteria:\n",
    "\n",
    "1. **Curricular Aspects**: Program design, curriculum development, and academic flexibility\n",
    "2. **Teaching-Learning and Evaluation**: Pedagogical practices and assessment methods\n",
    "3. **Research, Innovations and Extension**: Research culture and community engagement\n",
    "4. **Infrastructure and Learning Resources**: Physical and digital infrastructure\n",
    "5. **Student Support and Progression**: Student services and career development\n",
    "6. **Governance, Leadership and Management**: Administrative efficiency and leadership\n",
    "7. **Institutional Values and Best Practices**: Ethics, values, and innovative practices\n",
    "\n",
    "Each criterion has specific key indicators and metrics for evaluation.\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return f\"\"\"Thank you for your query about NAAC processes. Based on the available documentation, I can provide detailed guidance on NAAC accreditation, SSR preparation, criteria compliance, and best practices. \n",
    "\n",
    "For specific information about: {prompt[:100]}..., I recommend reviewing the relevant NAAC guidelines and consulting with your institution's IQAC (Internal Quality Assurance Cell).\n",
    "\n",
    "Would you like me to elaborate on any specific NAAC criterion or process?\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ibm_granite\"\n",
    "\n",
    "# Initialize the IBM Granite LLM\n",
    "print(\"ğŸ¤– Initializing IBM Granite LLM...\")\n",
    "granite_llm = IBMGraniteLLM()\n",
    "\n",
    "# Create retriever from vector database\n",
    "print(\"ğŸ” Setting up retriever...\")\n",
    "try:\n",
    "    retriever = vector_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 4}  # Retrieve top 4 most similar chunks\n",
    "    )\n",
    "    print(\"   âœ… Retriever configured successfully!\")\n",
    "except:\n",
    "    print(\"   âš ï¸  Using mock retriever for demonstration\")\n",
    "    retriever = None\n",
    "\n",
    "# Create RAG chain\n",
    "print(\"ğŸ”— Building RAG pipeline...\")\n",
    "if retriever:\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=granite_llm,\n",
    "        chain_type=\"stuff\",  # Combine all retrieved docs\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(\"   âœ… RAG pipeline created successfully!\")\n",
    "else:\n",
    "    print(\"   âš ï¸  RAG pipeline in demo mode\")\n",
    "    qa_chain = None\n",
    "\n",
    "print(f\"\\nğŸ‰ RAG Pipeline Setup Complete!\")\n",
    "print(f\"   ğŸ¤– LLM: IBM Granite (Mock mode: {granite_llm.mock_mode})\")\n",
    "print(f\"   ğŸ—„ï¸ Vector DB: ChromaDB with {len(all_chunks) if 'all_chunks' in locals() else 0} chunks\")\n",
    "print(f\"   ğŸ” Retriever: Top-4 similarity search\")\n",
    "print(f\"   ğŸ”— Chain Type: Stuff (combine retrieved documents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ef73a",
   "metadata": {},
   "source": [
    "## ğŸ§ª Section 8: Test the AI Assistant\n",
    "\n",
    "Create test queries related to NAAC processes, validate responses, and demonstrate the assistant's ability to generate SSR content and answer faculty questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naac_assistant(query, qa_chain=None):\n",
    "    \"\"\"Test the NAAC AI assistant with a query\"\"\"\n",
    "    print(f\"ğŸ” Query: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    if qa_chain:\n",
    "        try:\n",
    "            result = qa_chain({\"query\": query})\n",
    "            response = result[\"result\"]\n",
    "            sources = result.get(\"source_documents\", [])\n",
    "            \n",
    "            print(f\"ğŸ¤– Response:\\n{response}\\n\")\n",
    "            \n",
    "            if sources:\n",
    "                print(f\"ğŸ“š Sources ({len(sources)} documents):\")\n",
    "                for i, source in enumerate(sources, 1):\n",
    "                    source_name = source.metadata.get('source', 'Unknown')\n",
    "                    chunk_id = source.metadata.get('chunk_id', 'Unknown')\n",
    "                    preview = source.page_content[:150] + \"...\" if len(source.page_content) > 150 else source.page_content\n",
    "                    print(f\"   {i}. {source_name} ({chunk_id})\")\n",
    "                    print(f\"      {preview}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "            print(f\"ğŸ¤– Fallback Response: {granite_llm._generate_mock_response(query)}\")\n",
    "    else:\n",
    "        print(f\"ğŸ¤– Mock Response: {granite_llm._generate_mock_response(query)}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "# Test queries covering different NAAC aspects\n",
    "test_queries = [\n",
    "    \"What are the seven criteria for NAAC accreditation?\",\n",
    "    \"How should I write the executive summary for an SSR?\",\n",
    "    \"What documents are required for NAAC accreditation?\",\n",
    "    \"Explain the role of IQAC in quality assurance\",\n",
    "    \"What are the best practices for criterion 3 - Research and Innovation?\",\n",
    "    \"How to demonstrate student progression in NAAC evaluation?\",\n",
    "    \"What infrastructure requirements does NAAC specify?\",\n",
    "    \"Generate a sample introduction for SSR of a B.Ed college\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Testing NAAC AI Assistant\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"ğŸ”¬ Test {i}/{len(test_queries)}\")\n",
    "    test_naac_assistant(query, qa_chain)\n",
    "    \n",
    "    # Add a small delay between tests\n",
    "    import time\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ef6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query interface\n",
    "def interactive_naac_assistant():\n",
    "    \"\"\"Interactive interface for the NAAC AI assistant\"\"\"\n",
    "    print(\"ğŸ“ NAAC AI Assistant - Interactive Mode\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nğŸ’¬ Your Question: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"ğŸ‘‹ Thank you for using NAAC AI Assistant!\")\n",
    "                break\n",
    "                \n",
    "            if not query:\n",
    "                print(\"Please enter a valid question.\")\n",
    "                continue\n",
    "                \n",
    "            print()\n",
    "            test_naac_assistant(query, qa_chain)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ‘‹ Thank you for using NAAC AI Assistant!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}\")\n",
    "\n",
    "# Uncomment the line below to start interactive mode\n",
    "# interactive_naac_assistant()\n",
    "\n",
    "print(\"ğŸ¯ Ready for Interactive Use!\")\n",
    "print(\"   ğŸ’¡ Call interactive_naac_assistant() to start chatting\")\n",
    "print(\"   ğŸ“ Or use test_naac_assistant(query) for single queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a52eae",
   "metadata": {},
   "source": [
    "## âœ… Pipeline Complete - Summary & Next Steps\n",
    "\n",
    "### ğŸ‰ What We've Accomplished\n",
    "\n",
    "âœ… **Data Organization**: Structured raw data into organized directories  \n",
    "âœ… **Data Cleaning**: Processed CSV/Excel files with standardized formatting  \n",
    "âœ… **Text Extraction**: Extracted content from PDF documents  \n",
    "âœ… **Text Chunking**: Split documents into optimal retrieval segments  \n",
    "âœ… **Vector Database**: Created searchable embeddings with ChromaDB  \n",
    "âœ… **RAG Pipeline**: Built Retrieval-Augmented Generation system  \n",
    "âœ… **LLM Integration**: Connected with IBM Granite LLM  \n",
    "âœ… **Testing Suite**: Validated assistant capabilities  \n",
    "\n",
    "### ğŸš€ Your NAAC AI Assistant Can Now:\n",
    "\n",
    "- ğŸ“Š **Answer NAAC Queries**: Respond to questions about accreditation criteria\n",
    "- ğŸ“ **Generate SSR Content**: Help write Self Study Report sections\n",
    "- ğŸ” **Search Documents**: Find relevant information from NAAC guidelines\n",
    "- ğŸ“‹ **Provide Guidance**: Offer step-by-step NAAC process guidance\n",
    "- ğŸ¯ **Support Faculty**: Answer institutional queries and provide templates\n",
    "\n",
    "### ğŸ› ï¸ Next Steps for Production:\n",
    "\n",
    "1. **Add More Documents**: Place additional NAAC PDFs in `/data/documents/`\n",
    "2. **Enhance Data**: Add more institutional datasets to `/data/raw/`\n",
    "3. **Deploy Backend**: Use the FastAPI backend for web integration\n",
    "4. **Frontend Integration**: Connect with your React application\n",
    "5. **Fine-tune Responses**: Adjust prompts and retrieval parameters\n",
    "6. **Add Authentication**: Implement user access controls\n",
    "7. **Monitor Usage**: Track queries and improve responses\n",
    "\n",
    "### ğŸ“‚ Generated Files:\n",
    "\n",
    "- `data/cleaned/`: Processed CSV/Excel files\n",
    "- `data/processed/text_chunks.json`: Chunked text data\n",
    "- `data/processed/chroma_db/`: Vector database\n",
    "- `data/processed/vector_db_metadata.json`: Database configuration\n",
    "\n",
    "### ğŸ”§ Usage Examples:\n",
    "\n",
    "```python\n",
    "# Query the assistant\n",
    "response = test_naac_assistant(\"How to write criterion 2 for SSR?\")\n",
    "\n",
    "# Interactive mode\n",
    "interactive_naac_assistant()\n",
    "\n",
    "# Direct LLM access\n",
    "granite_response = granite_llm(\"Explain NAAC grading system\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“ Your NAAC AI Assistant is ready to help with accreditation processes!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
